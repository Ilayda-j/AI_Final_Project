# AI Final Project: Automated Fake News Detector for Social Media

## **Introduction**

### **Motivation**

The rise of misinformation on social media presents an intriguing and challenging problem for algorithm design. Fake news not only spreads faster than truthful content but also exploits linguistic and contextual nuances, making it a compelling subject for advanced AI applications. This project is motivated by the opportunity to explore and implement state-of-the-art algorithms to address a real-world problem within a controlled academic framework.

Building an Automated Fake News Detector provides a platform to apply and integrate a variety of machine learning and natural language processing (NLP) techniques. It challenges us to design and evaluate algorithms capable of distinguishing between fake and real news with high accuracy while maintaining transparency and interpretability.

This project also provides a valuable learning opportunity to:

- Experiment with feature engineering, decision tree-based models, recurrent neural networks (RNN/LSTM), and transformer-based architectures.
- Evaluate algorithms using established datasets such as LIAR and FakeNewsNet.
- Analyze and compare performance metrics to determine the most effective approach.
By addressing the technical and analytical aspects of this problem, this project allows us to deepen our understanding of AI methodologies while contributing a meaningful solution to an increasingly relevant societal issue.

### **Contributions**

For this project, I introduced multiple AI approaches to achieve accurate and transparent misinformation detection. The key contributions include:

1. **Natural Language Processing (NLP)**: Extracts linguistic features from posts using tokenization, sentiment analysis, and Named Entity Recognition (NER).
2. **Decision Tree Models**: Implements Random Forest classifiers to identify patterns and classify text based on extracted features.
3. **Neural Networks (RNN/LSTM)**: Captures contextual dependencies and temporal patterns within the text for nuanced fake news detection.
4. **Transformer-based Models (e.g., BERT/RoBERTa)**: Provides sophisticated context and semantic understanding for detecting subtle misinformation.

## **Solution Formulation**

### **AI Techniques Implemented**

This project uses a combination of AI techniques to tackle the problem of detecting fake news on social media. Each method contributes to different aspects of the solution, helping the system analyze text content, extract meaningful features, and make accurate predictions. Below, we describe the techniques we implemented, their roles in solving the problem, and why they were chosen.

---

### **1. Natural Language Processing (NLP)**

#### **Steps:**
1. **Tokenization**:
   - The text is split into individual words or tokens to analyze linguistic features like word counts and keyword frequencies.
   - Example:
     ```
     Input: "Breaking news: Aliens have landed on Earth!"
     Tokens: ["Breaking", "news", ":", "Aliens", "have", "landed", "on", "Earth", "!"]
     ```
   - **Role**: Helps identify structural patterns, such as text complexity, and locate keywords.

2. **Sentiment Analysis**:
   - We calculate the emotional tone of the text using scores for positive, negative, and neutral sentiment, as well as an overall "compound" score.
   - Fake news often exaggerates emotions, so strong sentiment is flagged as a potential indicator.
   - Example:
     ```
     Input: "Shocking discovery changes everything!"
     Sentiment Scores: {'neg': 0.2, 'neu': 0.4, 'pos': 0.4, 'compound': 0.7}
     ```
   - **Role**: Identifies exaggerated or emotionally charged language often seen in fake news.

3. **Named Entity Recognition (NER)**:
   - Proper nouns (e.g., organizations, locations, people) are extracted to assess credibility.
   - Example:
     ```
     Input: "NASA discovers water on Mars."
     Output: [('NASA', 'ORGANIZATION'), ('Mars', 'GPE')]
     ```
   - **Role**: Fake news often lacks references to credible entities or uses irrelevant ones, which NER helps identify.

#### **Why NLP?**
Natural Language Processing (NLP) is a fundamental part of this project because it enables the system to extract meaningful insights from raw text data, which is inherently unstructured and complex. Social media posts are highly variable in language style, length, and tone, and NLP provides the tools to handle these variations systematically.
It enables the system to:

Extract patterns from text data.
Represent unstructured information in a structured format.
Provide interpretable insights for both users and machine learning models. By bridging the gap between unstructured text and structured analysis, NLP ensures the system is both robust and scalable for real-world applications.
---

### **2. Decision Tree Models (Random Forest)**

#### **Steps:**
1. Extract the features generated by the NLP pipeline.
2. Train a **Random Forest Classifier**, which creates multiple decision trees using subsets of features and data:
   - Each tree makes a prediction, and the majority vote determines the final classification.
   - Example:
     ```
     Rule: IF sentiment_compound > 0.7 AND num_named_entities = 0 THEN classify as Fake.
     ```
3. Evaluate the model's performance on the test dataset using accuracy, precision, recall, and F1 score.

#### **Pseudo Code:**
```python
# Train a Random Forest Classifier
from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(n_estimators=200, max_depth=10)
rf_model.fit(X_train, y_train)

# Predict and evaluate
predictions = rf_model.predict(X_test)
